import os
import pandas as pd
import json
import glob
import time

# IDEì˜ ë¹¨ê°„ ì¤„(Import ì—ëŸ¬)ì„ ë°©ì§€í•˜ê¸° ìœ„í•œ ë°©ì‹
try:
    from google import generativeai as genai
except ImportError:
    print("âŒ íŒ¨í‚¤ì§€ê°€ ì—†ìŠµë‹ˆë‹¤. í„°ë¯¸ë„ì—ì„œ 'pip install -U google-generativeai'ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")

# ==========================================
# 1. ì„¤ì • (ì‚¬ìš©ì ìˆ˜ì • í•„ìš”)
# ==========================================
GENAI_API_KEY = "AIzaSyAWzeQ1b4Mrb4XfpJJG8LwtUNqkTBF_2GM"  # ë°œê¸‰ë°›ì€ API í‚¤ ì…ë ¥
genai.configure(api_key=GENAI_API_KEY)

# ëª¨ë¸ ì„¤ì • (ê¸´ í…ìŠ¤íŠ¸ ë¶„ì„ì— ìµœì í™”ëœ Pro ëª¨ë¸ ê¶Œì¥)
model = genai.GenerativeModel('gemini-3-pro-preview')

INPUT_FOLDER = "EXTRACTED_TEXT"  # Seleniumìœ¼ë¡œ ë½‘ì€ í…ìŠ¤íŠ¸ í´ë”
METADATA_CSV = "20250409_LipidLibrarySample.xlsx"  # ê¸°ì¡´ ë©”íƒ€ë°ì´í„°
OUTPUT_FILE = "LNP_Experimental_Database_Final.xlsx"

# ==========================================
# 2. ê³ ë„í™”ëœ LNPDB ì¶”ì¶œ í”„ë¡¬í”„íŠ¸
# ==========================================
SYSTEM_PROMPT = """
ë‹¹ì‹ ì€ ì§€ì§ˆ ë‚˜ë…¸ì…ì(LNP) íŠ¹í—ˆ ë¬¸í—Œì—ì„œ ì‹¤í—˜ ë°ì´í„°ë¥¼ êµ¬ì¡°í™”í•˜ì—¬ ì¶”ì¶œí•˜ëŠ” ì „ë¬¸ ë¶„ì„ê°€ì…ë‹ˆë‹¤.
ì œê³µëœ í…ìŠ¤íŠ¸ì—ì„œ 'ì‹¤ì œ ì‹¤í—˜(Examples)' ë° 'ê²°ê³¼ ë°ì´í„°(Tables)'ë¥¼ ì°¾ì•„ ì•„ë˜ ìŠ¤í‚¤ë§ˆì— ë§ì¶° ì¶”ì¶œí•˜ì„¸ìš”.

[í•µì‹¬ ê·œì¹™]
1. ë¡œìš° ë¶„ë¦¬: í•˜ë‚˜ì˜ íŠ¹í—ˆ ë‚´ì—ì„œ ì´ì˜¨í™” ì§€ì§ˆ(IL), ì¡°ì„±ë¹„, ì‹¤í—˜ ëª¨ë¸ ì¤‘ í•˜ë‚˜ë¼ë„ ë‹¤ë¥´ë©´ ë³„ê°œì˜ JSON ê°ì²´ë¡œ ìƒì„±í•˜ì„¸ìš”.
2. ì‹¤ì œ ë°ì´í„° ìš°ì„ : Claimsê°€ ì•„ë‹Œ ì‹¤ì œ ì œì¡° ë° í…ŒìŠ¤íŠ¸ëœ 'Examples' ìˆ˜ì¹˜ì— ì§‘ì¤‘í•˜ì„¸ìš”.
3. ID ìƒì„±: 'ì €ì/ì¶œì›ì¸ ì´ë‹ˆì…œ_ì¶œì›ì—°ë„_ìˆœë²ˆ' (ì˜ˆ: GT_2021_1, GT_2021_2) í˜•ì‹ìœ¼ë¡œ Experiment_IDë¥¼ ë§Œë“œì„¸ìš”.
4. ë°ì´í„°ê°€ ì—†ëŠ” í•­ëª©ì€ "N/A" ë˜ëŠ” ê³µë°±ìœ¼ë¡œ ë‘ì„¸ìš”.

ë°˜ë“œì‹œ ì•„ë˜ í•„ë“œë¥¼ í¬í•¨í•œ JSON ë¦¬ìŠ¤íŠ¸([...])ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”:
{
  "Experiment_ID": "ID (ì˜ˆ: GT_2021_1)",
  "IL_name": "ì´ì˜¨í™” ì§€ì§ˆ ëª…ì¹­",
  "IL_SMILES": "ì´ì˜¨í™” ì§€ì§ˆ ì „ì²´ SMILES",
  "IL_head_name": "Amine head ëª…ì¹­",
  "IL_head_SMILES": "Amine head SMILES",
  "IL_linker_name": "Linker ëª…ì¹­",
  "IL_linker_SMILES": "Linker SMILES",
  "IL_tail1_name": "Tail1 ëª…ì¹­",
  "IL_tail1_SMILES": "Tail1 SMILES",
  "IL_tail2_name": "Tail2 ëª…ì¹­",
  "IL_tail2_SMILES": "Tail2 SMILES",
  "IL_molratio": "IL ëª°ë¹„(0-100)",
  "IL_to_nucleicacid_massratio": "IL/í•µì‚° ì§ˆëŸ‰ë¹„",
  "IL_to_nucleicacid_chargeratio": "N/P ratio",
  "HL_name": "Helper Lipid ëª…ì¹­",
  "HL_SMILES": "Helper Lipid SMILES",
  "HL_molratio": "HL ëª°ë¹„",
  "CHL_name": "Cholesterol ëª…ì¹­",
  "CHL_SMILES": "Cholesterol SMILES",
  "CHL_molratio": "Cholesterol ëª°ë¹„",
  "PEG_name": "PEG ì§€ì§ˆ ëª…ì¹­",
  "PEG_SMILES": "PEG ì§€ì§ˆ SMILES",
  "PEG_molratio": "PEG ëª°ë¹„",
  "fifthcomponent_name": "ì œ5ì„±ë¶„ ëª…ì¹­",
  "fifthcomponent_SMILES": "ì œ5ì„±ë¶„ SMILES",
  "fifthcomponent_molratio": "ì œ5ì„±ë¶„ ëª°ë¹„",
  "Aqueous_buffer": "ìˆ˜ìƒ ë²„í¼ (acetate/citrate ë“±)",
  "Dialysis_buffer": "íˆ¬ì„ ë²„í¼ (PBS/None ë“±)",
  "Mixing_method": "í˜¼í•©ë°©ë²• (microfluidics ë“±)",
  "Model": "in_vitro ë˜ëŠ” in_vivo",
  "Model_type": "ì„¸í¬ì£¼ ë˜ëŠ” ë™ë¬¼ì¢…",
  "Model_target": "íƒ€ê²Ÿ ì¡°ì§/ì¥ê¸°",
  "Route_of_administration": "íˆ¬ì—¬ ê²½ë¡œ",
  "Cargo": "íƒ‘ì¬ ë‹¨ë°±ì§ˆ/ìœ ì „ì ì´ë¦„",
  "Cargo_type": "í•µì‚° ì¢…ë¥˜ (mRNA/siRNA ë“±)",
  "Dose_ug_nucleicacid": "íˆ¬ì—¬ëŸ‰(ug)",
  "Experiment_method": "ì¸¡ì • ë°©ë²• (luminescence ë“±)",
  "Experiment_batching": "individual ë˜ëŠ” barcoded",
  "Experiment_value": "ì‹¤í—˜ ê²°ê³¼ ìˆ˜ì¹˜"
}
"""


# ==========================================
# 3. ë¶„ì„ ë° ì¶”ì¶œ ì‹¤í–‰ ë¡œì§
# ==========================================
def run_lnpdb_extraction():
    # ë©”íƒ€ë°ì´í„° ë¡œë“œ
    try:
        meta_df = pd.read_excel(METADATA_CSV)
        print(f"ğŸ“Š ë©”íƒ€ë°ì´í„° ë¡œë“œ ì„±ê³µ: {len(meta_df)}ê±´")
    except Exception as e:
        print(f"âš ï¸ ë©”íƒ€ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        meta_df = pd.DataFrame()

    all_rows = []
    txt_files = glob.glob(os.path.join(INPUT_FOLDER, "*.txt"))

    if not txt_files:
        print(f"âŒ '{INPUT_FOLDER}' í´ë”ì— í…ìŠ¤íŠ¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    for file_path in txt_files:
        patent_id = os.path.basename(file_path).replace(".txt", "")
        print(f"ğŸ” ë¶„ì„ ì¤‘... {patent_id}")

        # ë©”íƒ€ë°ì´í„° ë§¤ì¹­ (Applicant, Link ë“± ë³´ì¡´)
        current_meta = {}
        if not meta_df.empty and patent_id in meta_df['PATENT_ID'].values:
            current_meta = meta_df[meta_df['PATENT_ID'] == patent_id].iloc[0].to_dict()
        else:
            current_meta = {"PATENT_ID": patent_id}

        with open(file_path, "r", encoding="utf-8") as f:
            content = f.read()

        try:
            # Gemini API í˜¸ì¶œ (Native JSON ëª¨ë“œ)
            response = model.generate_content(
                f"{SYSTEM_PROMPT}\n\n[íŠ¹í—ˆ ë³¸ë¬¸]\n{content[:30000]}",
                generation_config={"response_mime_type": "application/json", "temperature": 0.1}
            )

            extracted_data = json.loads(response.text)

            # ë¦¬ìŠ¤íŠ¸ í˜•íƒœê°€ ì•„ë‹ˆë©´ ë³€í™˜
            if isinstance(extracted_data, dict):
                extracted_data = [extracted_data]

            # ê° ì‹¤í—˜ë³„ë¡œ ë¡œìš° ìƒì„± ë° ë©”íƒ€ë°ì´í„° ê²°í•©
            for exp in extracted_data:
                combined_row = {**current_meta, **exp}
                all_rows.append(combined_row)

            print(f"   âœ… {len(extracted_data)}ê°œì˜ ì‹¤í—˜ ë°ì´í„° í–‰ì„ ìƒì„±í–ˆìŠµë‹ˆë‹¤.")

        except Exception as e:
            print(f"   âŒ {patent_id} ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

        # API í• ë‹¹ëŸ‰ ê³ ë ¤
        time.sleep(2)

    # ì—‘ì…€ ì €ì¥
    if all_rows:
        df_final = pd.DataFrame(all_rows)
        # ì»¬ëŸ¼ ìˆœì„œ ì •ë¦¬ (í•„ìš” ì‹œ ì¡°ì ˆ)
        df_final.to_excel(OUTPUT_FILE, index=False)
        print(f"\nâœ¨ ëª¨ë“  ì‘ì—… ì™„ë£Œ! íŒŒì¼ ì €ì¥ë¨: {OUTPUT_FILE}")
    else:
        print("âŒ ì¶”ì¶œëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")


if __name__ == "__main__":
    run_lnpdb_extraction()