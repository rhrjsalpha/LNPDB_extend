import ollama
import json
import re
import fitz  # PyMuPDF
from typing import List, Dict, Any

# ============================================================
# ìœ í‹¸ í•¨ìˆ˜
# ============================================================

def remove_think_block(text: str) -> str:
    """<think>...</think> ë¸”ë¡ ì œê±°"""
    return re.sub(
        r"<think>.*?</think>",
        "",
        text,
        flags=re.DOTALL | re.IGNORECASE
    ).strip()


def extract_json_only(text: str) -> str:
    """
    LLM ì¶œë ¥ì—ì„œ ```json ... ``` ë˜ëŠ” ``` ... ``` ì œê±° í›„
    JSON ë³¸ë¬¸ë§Œ ë°˜í™˜
    """
    text = remove_think_block(text)

    # ```json ... ``` í˜•íƒœ
    m = re.search(
        r"```(?:json)?\s*(\{.*?\})\s*```",
        text,
        re.DOTALL | re.IGNORECASE
    )
    if m:
        return m.group(1).strip()

    # fallback: ì²« { ~ ë§ˆì§€ë§‰ }
    m = re.search(r"(\{.*\})", text, re.DOTALL)
    if m:
        return m.group(1).strip()

    raise ValueError("JSON ê°ì²´ë¥¼ ì°¾ì§€ ëª»í•¨")


def iter_pdf_pages(pdf_path: str):
    """PDFë¥¼ í˜ì´ì§€ ë‹¨ìœ„ë¡œ ìˆœíšŒ"""
    doc = fitz.open(pdf_path)
    for page_idx, page in enumerate(doc, start=1):
        text = page.get_text("text").strip()
        if text:
            yield page_idx, text
    doc.close()

# ============================================================
# ì„¤ì •
# ============================================================

PDF_FILE = "MP_2025.pdf"   # â† í•„ìš”ì‹œ MP_2025_SI.pdf ë¡œ ë³€ê²½
THINK_MODEL = "jinbora/deepseek-r1-Bllossom:8b"
JSON_MODEL  = "jinbora/deepseek-r1-Bllossom:8b"

# ============================================================
# í”„ë¡¬í”„íŠ¸
# ============================================================

THINK_PROMPT = """
ë‹¤ìŒ TEXTë¥¼ ì½ê³ 
LNP (Lipid Nanoparticle) ì¡°ì„± ì •ë³´ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ì •ë¦¬í•˜ë¼.

ì¶œë ¥ ê·œì¹™ (ì¤‘ìš”):
- TEXTì—ì„œ LNP ì¡°ì„± ì •ë³´ê°€ í•˜ë‚˜ë„ ì—†ìœ¼ë©´
  ë°˜ë“œì‹œ ì•„ë˜ í•œ ì¤„ë§Œ ì •í™•íˆ ì¶œë ¥í•˜ë¼.

ì—†ìŒ

- ìœ„ ê²½ìš°ë¥¼ ì œì™¸í•˜ê³ ëŠ” "ì—†ìŒ"ì´ë¼ëŠ” ë‹¨ì–´ë¥¼ ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆë¼.
- ë¶ˆí™•ì‹¤í•˜ê±°ë‚˜ ì¶”ë¡ ì´ í•„ìš”í•œ ê²½ìš°ì—ë„ ì¶”ë¡ í•˜ì§€ ë§ê³  "ì—†ìŒ"ìœ¼ë¡œ ì²˜ë¦¬í•˜ë¼.
- ì›ë¬¸ì— ì—†ëŠ” ì •ë³´ëŠ” ì ˆëŒ€ ì¶”ê°€í•˜ì§€ ë§ˆë¼.

ì •ë¦¬ ê¸°ì¤€ (LNPê°€ ì¡´ì¬í•˜ëŠ” ê²½ìš°ì—ë§Œ ì ìš©):
- LNP ì´ë¦„ ë˜ëŠ” formulation êµ¬ë¶„
- í•µì‚° ì¢…ë¥˜ (mRNA, siRNA, pDNA ë“±)
- IL to nucleic acid mass ratio
- lipid ì´ë¦„ê³¼ molar ratio
- "respectively", "for B10 formulation" ë“±ì˜ ë¬¸ë§¥ì„ ëª…í™•íˆ í’€ì–´ì„œ ì‘ì„±

ì¶œë ¥ í˜•ì‹ (ì˜ˆì‹œ):

LNP1:
- mRNA
- IL 10 : nucleic acid 1
- lipid name 1 : ratio
- lipid name 2 : ratio
- lipid name 3 : ratio
- lipid name 4 : ratio

LNP2:
- sgRNA
- IL 10 : nucleic acid 1
- lipid name 1 : ratio
- lipid name 2 : ratio
- lipid name 3 : ratio
- lipid name 4 : ratio

TEXT:
"""


JSON_PROMPT = """
ë„ˆëŠ” ì •ë³´ ë³€í™˜ê¸°ì´ë‹¤.

ì•„ë˜ SUMMARYì—ì„œ LNP ì¡°ì„± ì •ë³´ë¥¼ ì¶”ì¶œí•˜ë¼.

ì¶œë ¥ ê·œì¹™:
- ë°˜ë“œì‹œ JSONë§Œ ì¶œë ¥í•˜ë¼
- ì„¤ëª…, ë¬¸ì¥, ì£¼ì„ ì¶œë ¥ ê¸ˆì§€
- ê°’ì´ ì—†ìœ¼ë©´ nullë¡œ ì±„ì›Œë¼
- ì—¬ëŸ¬ LNPê°€ ìˆìœ¼ë©´ ë°°ì—´ë¡œ ì¶œë ¥í•˜ë¼

JSON ìŠ¤í‚¤ë§ˆ:
{
  "LNPs": [
    {
      "LNP_name": string | null,
      "Nucleic_acid": "mRNA" | "siRNA" | "pDNA" | null,
      "IL_to_Nucleic_Acid_Mass_Ratio": string | null,
      "Lipids": {
        "Ionizable_lipid": string | null,
        "Helper_lipid": string | null,
        "Cholesterol": string | null,
        "PEG_lipid": string | null
      },
      "Molar_ratios": {
        "Ionizable_lipid": number | string | null,
        "Helper_lipid": number | string | null,
        "Cholesterol": number | string | null,
        "PEG_lipid": number | string | null
      }
    }
  ]
}

SUMMARY:
"""

# ============================================================
# ë©”ì¸ íŒŒì´í”„ë¼ì¸ (í˜ì´ì§€ ë‹¨ìœ„)
# ============================================================

all_lnps: List[Dict[str, Any]] = []

START_PAGE = 12   # ì‹œì‘ í˜ì´ì§€ (1-indexed)
END_PAGE   = 16  # ë í˜ì´ì§€ (í¬í•¨)
for page_idx, page_text in iter_pdf_pages(PDF_FILE):
    if page_idx < START_PAGE:
        continue
    if page_idx > END_PAGE:
        break
    print(f"\n================ PAGE {page_idx} =================")

    try:
        # ---------- STEP 1: THINK ----------
        think_response = ollama.generate(
            model=THINK_MODEL,
            prompt=THINK_PROMPT + page_text,
            options={"temperature": 0}
        )

        summary_text = remove_think_block(think_response["response"])
        print(summary_text)

        if not summary_text.strip():
            print("âš ï¸ ìš”ì•½ ê²°ê³¼ ì—†ìŒ â†’ í˜ì´ì§€ ìŠ¤í‚µ")
            continue

        # ---------- STEP 2: JSON ----------
        json_response = ollama.generate(
            model=JSON_MODEL,
            prompt=JSON_PROMPT + summary_text,
            options={"temperature": 0}
        )

        json_text = extract_json_only(json_response["response"])

        data = json.loads(json_text)

        # ---------- ê²°ê³¼ ëˆ„ì  ----------
        lnps = data.get("LNPs", [])
        if lnps:
            for lnp in lnps:
                lnp["_source_page"] = page_idx
            all_lnps.extend(lnps)
            print(f"âœ… LNP {len(lnps)}ê°œ ì¶”ì¶œ")
        else:
            print("â„¹ï¸ LNP ì—†ìŒ")

    except Exception as e:
        print(f"âŒ PAGE {page_idx} ì‹¤íŒ¨: {e}")

# ============================================================
# ìµœì¢… ê²°ê³¼ ì¶œë ¥
# ============================================================

print("\n================ FINAL RESULT ================\n")
print(json.dumps(all_lnps, indent=2, ensure_ascii=False))

# í•„ìš” ì‹œ íŒŒì¼ ì €ì¥
with open("lnp_extracted_from_pdf.json", "w", encoding="utf-8") as f:
    json.dump(all_lnps, f, indent=2, ensure_ascii=False)

print(f"\nğŸ’¾ ì €ì¥ ì™„ë£Œ: lnp_extracted_from_pdf.json (ì´ {len(all_lnps)} LNP)")

# ============================================================
# CSV ë³€í™˜
# ============================================================

import csv

csv_rows = []

for lnp in all_lnps:
    row = {
        "source_page": lnp.get("_source_page"),
        "LNP_name": lnp.get("LNP_name"),
        "Nucleic_Acid": lnp.get("Nucleic_acid"),
        "IL_to_Nucleic_Acid_Mass_Ratio": lnp.get("IL_to_Nucleic_Acid_Mass_Ratio"),

        "Ionizable_lipid": lnp.get("Lipids", {}).get("Ionizable_lipid"),
        "Helper_lipid": lnp.get("Lipids", {}).get("Helper_lipid"),
        "Cholesterol": lnp.get("Lipids", {}).get("Cholesterol"),
        "PEG_lipid": lnp.get("Lipids", {}).get("PEG_lipid"),

        "Ionizable_lipid_ratio": lnp.get("Molar_ratios", {}).get("Ionizable_lipid"),
        "Helper_lipid_ratio": lnp.get("Molar_ratios", {}).get("Helper_lipid"),
        "Cholesterol_ratio": lnp.get("Molar_ratios", {}).get("Cholesterol"),
        "PEG_lipid_ratio": lnp.get("Molar_ratios", {}).get("PEG_lipid"),
    }
    csv_rows.append(row)

csv_file = "lnp_extracted_from_pdf.csv"

with open(csv_file, "w", newline="", encoding="utf-8-sig") as f:
    writer = csv.DictWriter(f, fieldnames=csv_rows[0].keys())
    writer.writeheader()
    writer.writerows(csv_rows)

print(f"\nğŸ“„ CSV ì €ì¥ ì™„ë£Œ: {csv_file} (ì´ {len(csv_rows)} rows)")